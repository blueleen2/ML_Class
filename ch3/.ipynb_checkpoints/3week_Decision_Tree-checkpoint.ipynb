{
 "metadata": {
  "name": "",
  "signature": "sha256:fb91cc00f977a43a46b783c60920a846db9565ebcc45b8792d9f5b05ee74b20a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import trees\n",
      "import treePlotter\n",
      "\n",
      "#\ub370\uc774\ud130\ub85c\ub4dc \n",
      "def createDataSet():\n",
      "    dataSet = [[1, 1, 'yes'],\n",
      "               [1, 1, 'yes'],\n",
      "               [1, 0, 'no'],\n",
      "               [0, 1, 'no'],\n",
      "               [0, 1, 'no']]\n",
      "    labels = ['no surfacing','flippers']\n",
      "    #change to discrete values\n",
      "    return dataSet, labels\n",
      "\n",
      "myDat, labels=trees.createDataSet()\n",
      "\n",
      "myDat\n",
      "       "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calcShannonEnt(dataSet):\n",
      "    numEntries = len(dataSet)\n",
      "    labelCounts = {}\n",
      "    for featVec in dataSet: #the the number of unique elements and their occurance\n",
      "        currentLabel = featVec[-1]\n",
      "        if currentLabel not in labelCounts.keys(): labelCounts[currentLabel] = 0\n",
      "        labelCounts[currentLabel] += 1\n",
      "    shannonEnt = 0.0\n",
      "    for key in labelCounts:\n",
      "        prob = float(labelCounts[key])/numEntries\n",
      "        shannonEnt -= prob * log(prob,2) #log base 2\n",
      "    return shannonEnt\n",
      "#\uc5d4\ud2b8\ub85c\ud53c \uacc4\uc0b0 \ud568\uc218 \n",
      "trees.calcShannonEnt(myDat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "0.9709505944546686"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def splitDataSet(dataSet, axis, value):\n",
      "    retDataSet = []\n",
      "    for featVec in dataSet:\n",
      "        if featVec[axis] == value:\n",
      "            reducedFeatVec = featVec[:axis]     #chop out axis used for splitting\n",
      "            reducedFeatVec.extend(featVec[axis+1:])\n",
      "            retDataSet.append(reducedFeatVec)\n",
      "    return retDataSet\n",
      "#\ub450\ubc88\uc9f8\uc778\uc790\ub294 \uc5f4\uc744 \ub9d0\ud558\uba70, \uc138\ubc88\uc9f8\uc778\uc790\ub294 \ub9e4\uce6d\ub418\ub294 \uac12\uc744 \ucd94\ucd9c\ud558\uae30 \uc704\ud574 \uc785\ub825  \n",
      "trees.splitDataSet(myDat,0,1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "[[1, 'yes'], [1, 'yes'], [0, 'no']]"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trees.splitDataSet(myDat,0,0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "[[1, 'no'], [1, 'no']]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def chooseBestFeatureToSplit(dataSet):\n",
      "    numFeatures = len(dataSet[0]) - 1      #the last column is used for the labels\n",
      "    baseEntropy = calcShannonEnt(dataSet)\n",
      "    bestInfoGain = 0.0; bestFeature = -1\n",
      "    for i in range(numFeatures):        #iterate over all the features\n",
      "        featList = [example[i] for example in dataSet]#create a list of all the examples of this feature\n",
      "        uniqueVals = set(featList)       #get a set of unique values\n",
      "        newEntropy = 0.0\n",
      "        for value in uniqueVals:\n",
      "            subDataSet = splitDataSet(dataSet, i, value)\n",
      "            prob = len(subDataSet)/float(len(dataSet))\n",
      "            newEntropy += prob * calcShannonEnt(subDataSet)     \n",
      "        infoGain = baseEntropy - newEntropy     #calculate the info gain; ie reduction in entropy\n",
      "        if (infoGain > bestInfoGain):       #compare this to the best gain so far\n",
      "            bestInfoGain = infoGain         #if better than current best, set to best\n",
      "            bestFeature = i\n",
      "    return bestFeature    \n",
      "#information Gain\uc744 \uacc4\uc0b0\ud558\uc5ec \uac00\uc7a5 \ub192\uc740 \uac12\uc744 \ubcf4\uc774\ub294 Feature\ub97c \uc120\uc815 \ud558\uc5ec \ub9ac\ud134\ud568 \n",
      "print trees.chooseBestFeatureToSplit(myDat)\n",
      "print myDat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Tree building \ucf54\ub4dc \n",
      "\n",
      "def createTree(dataSet,labels):\n",
      "    classList = [example[-1] for example in dataSet]\n",
      "    print classList\n",
      "    if classList.count(classList[0]) == len(classList): \n",
      "        return classList[0]#stop splitting when all of the classes are equal\n",
      "    if len(dataSet[0]) == 1: #stop splitting when there are no more features in dataSet\n",
      "        return majorityCnt(classList)\n",
      "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
      "    bestFeatLabel = labels[bestFeat]\n",
      "    myTree = {bestFeatLabel:{}}\n",
      "    del(labels[bestFeat])\n",
      "    featValues = [example[bestFeat] for example in dataSet]\n",
      "    uniqueVals = set(featValues)\n",
      "    for value in uniqueVals: \n",
      "        subLabels = labels[:]       #copy all of labels, so trees don't mess up existing labels\n",
      "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value),subLabels)\n",
      "    return myTree     \n",
      "\n",
      "myTree = createTree(myDat, labels)\n",
      "\n",
      "myTree\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['yes', 'yes', 'no', 'no', 'no']\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "global name 'log' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-6-9d9ba02dbd43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmyTree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mmyTree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyDat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mmyTree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-6-9d9ba02dbd43>\u001b[0m in \u001b[0;36mcreateTree\u001b[1;34m(dataSet, labels)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#stop splitting when there are no more features in dataSet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmajorityCnt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mbestFeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchooseBestFeatureToSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mbestFeatLabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbestFeat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mmyTree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mbestFeatLabel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-5-6aef32aa021c>\u001b[0m in \u001b[0;36mchooseBestFeatureToSplit\u001b[1;34m(dataSet)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mchooseBestFeatureToSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mnumFeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m      \u001b[1;31m#the last column is used for the labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mbaseEntropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalcShannonEnt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mbestInfoGain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mbestFeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumFeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m        \u001b[1;31m#iterate over all the features\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-2-9a11a38ff2b8>\u001b[0m in \u001b[0;36mcalcShannonEnt\u001b[1;34m(dataSet)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabelCounts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabelCounts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnumEntries\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mshannonEnt\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#log base 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mshannonEnt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#\uc5d4\ud2b8\ub85c\ud53c \uacc4\uc0b0 \ud568\uc218\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: global name 'log' is not defined"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treePlotter.createPlot(myTree)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Users\\SMUEE\\Anaconda\\lib\\site-packages\\matplotlib\\patches.py:3145: RuntimeWarning: invalid value encountered in double_scalars\n",
        "  ddx = pad_projected * dx / cp_distance\n",
        "C:\\Users\\SMUEE\\Anaconda\\lib\\site-packages\\matplotlib\\patches.py:3146: RuntimeWarning: invalid value encountered in double_scalars\n",
        "  ddy = pad_projected * dy / cp_distance\n",
        "C:\\Users\\SMUEE\\Anaconda\\lib\\site-packages\\matplotlib\\patches.py:3149: RuntimeWarning: invalid value encountered in double_scalars\n",
        "  dx = dx / cp_distance * head_dist\n",
        "C:\\Users\\SMUEE\\Anaconda\\lib\\site-packages\\matplotlib\\patches.py:3150: RuntimeWarning: invalid value encountered in double_scalars\n",
        "  dy = dy / cp_distance * head_dist\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def classify(inputTree,featLabels,testVec):\n",
      "    firstStr = inputTree.keys()[0]\n",
      "    secondDict = inputTree[firstStr]\n",
      "    featIndex = featLabels.index(firstStr)\n",
      "    key = testVec[featIndex]\n",
      "    valueOfFeat = secondDict[key]\n",
      "    if isinstance(valueOfFeat, dict): \n",
      "        classLabel = classify(valueOfFeat, featLabels, testVec)\n",
      "    else: classLabel = valueOfFeat\n",
      "    return classLabel\n",
      "\n",
      "myTree = treePlotter.retrieveTree (0)\n",
      "myTree\n",
      "trees.classify(myTree, labels, [1,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "'no'"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trees.classify(myTree, labels, [1,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "'yes'"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}