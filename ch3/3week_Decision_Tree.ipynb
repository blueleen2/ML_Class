{
 "metadata": {
  "name": "",
  "signature": "sha256:aff2df8041ee6a7d4c61b4d7861b207d40bb58802aabd5a37d5c1ea74fb71a35"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import trees\n",
      "import treePlotter\n",
      "\n",
      "#\ub370\uc774\ud130\ub85c\ub4dc \n",
      "def createDataSet():\n",
      "    dataSet = [[1, 1, 'yes'],\n",
      "               [1, 1, 'yes'],\n",
      "               [1, 0, 'no'],\n",
      "               [0, 1, 'no'],\n",
      "               [0, 1, 'no']]\n",
      "    labels = ['no surfacing','flippers']\n",
      "    #change to discrete values\n",
      "    return dataSet, labels\n",
      "\n",
      "myDat, labels=trees.createDataSet()\n",
      "\n",
      "myDat\n",
      "       "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calcShannonEnt(dataSet):\n",
      "    numEntries = len(dataSet)\n",
      "    labelCounts = {}\n",
      "    for featVec in dataSet: #the the number of unique elements and their occurance\n",
      "        currentLabel = featVec[-1]\n",
      "        if currentLabel not in labelCounts.keys(): labelCounts[currentLabel] = 0\n",
      "        labelCounts[currentLabel] += 1\n",
      "    shannonEnt = 0.0\n",
      "    for key in labelCounts:\n",
      "        prob = float(labelCounts[key])/numEntries\n",
      "        shannonEnt -= prob * log(prob,2) #log base 2\n",
      "    return shannonEnt\n",
      "#\uc5d4\ud2b8\ub85c\ud53c \uacc4\uc0b0 \ud568\uc218 \n",
      "trees.calcShannonEnt(myDat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "0.9709505944546686"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def splitDataSet(dataSet, axis, value):\n",
      "    retDataSet = []\n",
      "    for featVec in dataSet:\n",
      "        if featVec[axis] == value:\n",
      "            reducedFeatVec = featVec[:axis]     #chop out axis used for splitting\n",
      "            reducedFeatVec.extend(featVec[axis+1:])\n",
      "            retDataSet.append(reducedFeatVec)\n",
      "    return retDataSet\n",
      "#\ub450\ubc88\uc9f8\uc778\uc790\ub294 \uc5f4\uc744 \ub9d0\ud558\uba70, \uc138\ubc88\uc9f8\uc778\uc790\ub294 \ub9e4\uce6d\ub418\ub294 \uac12\uc744 \ucd94\ucd9c\ud558\uae30 \uc704\ud574 \uc785\ub825  \n",
      "trees.splitDataSet(myDat,0,1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "[[1, 'yes'], [1, 'yes'], [0, 'no']]"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trees.splitDataSet(myDat,0,0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "[[1, 'no'], [1, 'no']]"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def chooseBestFeatureToSplit(dataSet):\n",
      "    numFeatures = len(dataSet[0]) - 1      #the last column is used for the labels\n",
      "    baseEntropy = calcShannonEnt(dataSet)\n",
      "    bestInfoGain = 0.0; bestFeature = -1\n",
      "    for i in range(numFeatures):        #iterate over all the features\n",
      "        featList = [example[i] for example in dataSet]#create a list of all the examples of this feature\n",
      "        uniqueVals = set(featList)       #get a set of unique values\n",
      "        newEntropy = 0.0\n",
      "        for value in uniqueVals:\n",
      "            subDataSet = splitDataSet(dataSet, i, value)\n",
      "            prob = len(subDataSet)/float(len(dataSet))\n",
      "            newEntropy += prob * calcShannonEnt(subDataSet)     \n",
      "        infoGain = baseEntropy - newEntropy     #calculate the info gain; ie reduction in entropy\n",
      "        if (infoGain > bestInfoGain):       #compare this to the best gain so far\n",
      "            bestInfoGain = infoGain         #if better than current best, set to best\n",
      "            bestFeature = i\n",
      "    return bestFeature    \n",
      "#information Gain\uc744 \uacc4\uc0b0\ud558\uc5ec \uac00\uc7a5 \ub192\uc740 \uac12\uc744 \ubcf4\uc774\ub294 Feature\ub97c \uc120\uc815 \ud558\uc5ec \ub9ac\ud134\ud568 \n",
      "print trees.chooseBestFeatureToSplit(myDat)\n",
      "print myDat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Tree building \ucf54\ub4dc \n",
      "\n",
      "def createTree(dataSet,labels):\n",
      "    classList = [example[-1] for example in dataSet]\n",
      "    print classList\n",
      "    if classList.count(classList[0]) == len(classList): \n",
      "        return classList[0]#stop splitting when all of the classes are equal\n",
      "    if len(dataSet[0]) == 1: #stop splitting when there are no more features in dataSet\n",
      "        return majorityCnt(classList)\n",
      "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
      "    bestFeatLabel = labels[bestFeat]\n",
      "    myTree = {bestFeatLabel:{}}\n",
      "    del(labels[bestFeat])\n",
      "    featValues = [example[bestFeat] for example in dataSet]\n",
      "    uniqueVals = set(featValues)\n",
      "    for value in uniqueVals: \n",
      "        subLabels = labels[:]       #copy all of labels, so trees don't mess up existing labels\n",
      "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value),subLabels)\n",
      "    return myTree     \n",
      "\n",
      "myTree = trees.createTree(myDat, labels)\n",
      "\n",
      "myTree\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-58-2a1c0240cb87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmyTree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mmyTree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyDat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mmyTree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\SMUEE\\Desktop\\Machine Learning\\ML_Class\\trees.pyc\u001b[0m in \u001b[0;36mcreateTree\u001b[1;34m(dataSet, labels)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muniqueVals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0msubLabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m       \u001b[1;31m#copy all of labels, so trees don't mess up existing labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mmyTree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbestFeatLabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplitDataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestFeat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubLabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmyTree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\SMUEE\\Desktop\\Machine Learning\\ML_Class\\trees.pyc\u001b[0m in \u001b[0;36mcreateTree\u001b[1;34m(dataSet, labels)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmajorityCnt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mbestFeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchooseBestFeatureToSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mbestFeatLabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbestFeat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[0mmyTree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mbestFeatLabel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mdel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbestFeat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIndexError\u001b[0m: list index out of range"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treePlotter.createPlot(myTree)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Users\\SMUEE\\Anaconda\\lib\\site-packages\\matplotlib\\patches.py:3145: RuntimeWarning: invalid value encountered in double_scalars\n",
        "  ddx = pad_projected * dx / cp_distance\n",
        "C:\\Users\\SMUEE\\Anaconda\\lib\\site-packages\\matplotlib\\patches.py:3146: RuntimeWarning: invalid value encountered in double_scalars\n",
        "  ddy = pad_projected * dy / cp_distance\n",
        "C:\\Users\\SMUEE\\Anaconda\\lib\\site-packages\\matplotlib\\patches.py:3149: RuntimeWarning: invalid value encountered in double_scalars\n",
        "  dx = dx / cp_distance * head_dist\n",
        "C:\\Users\\SMUEE\\Anaconda\\lib\\site-packages\\matplotlib\\patches.py:3150: RuntimeWarning: invalid value encountered in double_scalars\n",
        "  dy = dy / cp_distance * head_dist\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def classify(inputTree,featLabels,testVec):\n",
      "    firstStr = inputTree.keys()[0]\n",
      "    secondDict = inputTree[firstStr]\n",
      "    featIndex = featLabels.index(firstStr)\n",
      "    key = testVec[featIndex]\n",
      "    valueOfFeat = secondDict[key]\n",
      "    if isinstance(valueOfFeat, dict): \n",
      "        classLabel = classify(valueOfFeat, featLabels, testVec)\n",
      "    else: classLabel = valueOfFeat\n",
      "    return classLabel\n",
      "\n",
      "myTree = treePlotter.retrieveTree (0)\n",
      "myTree\n",
      "trees.classify(myTree, labels, [1,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "'no'"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trees.classify(myTree, labels, [1,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "'yes'"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}