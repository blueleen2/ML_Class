{
 "metadata": {
  "name": "",
  "signature": "sha256:3f0d040cf4a3e77f86c96c15d2b444efe0d5b31da8ca76533516a3ae4dc54908"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Figure 4.1 Two probability distributions with known parameters describing the distribution\n",
      "\n",
      "1 Use kNN from chapter 1, and do 1,000 distance calculations.\n",
      "\n",
      "2 Use decision trees from chapter 2, and make a split of the data once along the\n",
      "x-axis and once along the y-axis.\n",
      "\n",
      "3 Compute the probability of each class, and compare them\n",
      "\n",
      "*The decision tree wouldn\u2019t be very successful, and kNN would require a lot of calculations compared to the simple probability calculation.\n",
      "\n",
      "process\n",
      "1. \ud655\ub960 \uad6c\ud558\uae30 -> 2, Likehood \n",
      "\n",
      "\n",
      "Bayes?(=Bayesian probability)\n",
      "There\u2019s another interpretation called frequency probability, which only draws conclusions from data and doesn\u2019t allow for logic and prior knowledge.\n",
      "\n",
      "This is known as conditional probability.\n",
      "\n",
      "General approach to na\u00efve Bayes\n",
      "1. Collect: Any method. We\u2019ll use RSS feeds in this chapter.\n",
      "2. Prepare: Numeric or Boolean values are needed.\n",
      "3. Analyze: With many features, plotting features isn\u2019t helpful. Looking at histograms\n",
      "is a better idea.\n",
      "4. Train: Calculate the conditional probabilities of the independent features.\n",
      "5. Test: Calculate the error rate.\n",
      "6. Use: One common application of na\u00efve Bayes is document classification. You\n",
      "can use na\u00efve Bayes in any classification setting. It doesn\u2019t have to be text.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import bayes\n",
      "from numpy import *\n",
      "%matplotlib inline\n",
      "\n",
      "listoPosts, listclasses = bayes.loadDataSet()\n",
      "\n",
      "print listclasses #DB\uc5d0 \ubb38\uc7a5\uc5d0 \ubaa8\uc695\uc801 \ub2e8\uc5b4\uac00 \uc788\ub294 \uc5ec\ubd80\ub97c \ud45c\uc2dc\ud55c \n",
      "\n",
      "print listoPosts[0] #loadDataSet\uc548\uc5d0 \uc788\ub294 \uccab\ubc88\uc9f8 \ub9ac\uc2a4\ud2b8\ub97c \uac00\uc838\uc634 \n",
      "\n",
      "myVocabList = bayes.createVocabList(listoPosts) #\ud558\ub098\ub85c \ud1b5\ud569\ud558\ub294 \uacfc\uc815 \uc911\ubcf5\uc740 \uc81c\uac70 \n",
      "\n",
      "print myVocabList\n",
      "\n",
      "def loadDataSet():\n",
      "    postingList=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
      "                 ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
      "                 ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
      "                 ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
      "                 ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
      "                 ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
      "    classVec = [0,1,0,1,0,1]    #1 is abusive, 0 not\n",
      "    return postingList,classVec\n",
      "                 \n",
      "def createVocabList(dataSet):\n",
      "    vocabSet = set([])  #create empty set\n",
      "    for document in dataSet:\n",
      "        vocabSet = vocabSet | set(document) #union of the two sets\n",
      "    return list(vocabSet)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0, 1, 0, 1, 0, 1]\n",
        "['my', 'dog', 'has', 'flea', 'problems', 'help', 'please']\n",
        "['cute', 'love', 'help', 'garbage', 'quit', 'I', 'problems', 'is', 'park', 'stop', 'flea', 'dalmation', 'licks', 'food', 'not', 'him', 'buying', 'posting', 'has', 'worthless', 'ate', 'to', 'maybe', 'please', 'dog', 'how', 'stupid', 'so', 'take', 'mr', 'steak', 'my']\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print myVocabList\n",
      "test = ['my', 'dog', 'has', 'ohho', 'problems', 'help', 'please']\n",
      "def setOfWords2Vec(vocabList, inputSet): #Union \uc744 \ud1b5\ud574 \ub9cc\ub4e0 \ub2e8\uc5b4\ub9ac\uc2a4\ud2b8\ub97c \ubca1\ud130\ub85c \ub9cc\ub4e4\uc5b4\uac00\ub294 \uacfc\uc815 \n",
      "    returnVec = [0]*len(vocabList) #32\uac1c 0\uc744 \uc138\ud305 \n",
      "    for word in inputSet:\n",
      "        if word in vocabList:\n",
      "            returnVec[vocabList.index(word)] = 1\n",
      "            #print vocabList.index(word)\n",
      "        else: print \"the word: %s is not in my Vocabulary!\" % word\n",
      "    return returnVec\n",
      "\n",
      "def bagOfWords2VecMN(vocabList, inputSet):\n",
      "    returnVec = [0]*len(vocabList)\n",
      "    for word in inputSet:\n",
      "        if word in vocabList:\n",
      "            returnVec[vocabList.index(word)] += 1\n",
      "    return returnVec\n",
      "\n",
      "mylistclasses = bayes.setOfWords2Vec(myVocabList, listoPosts[0]) #['my', 'dog', 'has', 'flea', 'problems', 'help', 'please']\n",
      "mylistclasses2 = bagOfWords2VecMN(myVocabList, test)\n",
      "print mylistclasses\n",
      "print mylistclasses2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1]\n",
        "[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1]\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#training\n",
      "\n",
      "def trainNB0(trainMatrix,trainCategory):\n",
      "    # \ucd08\uae30 \ud655\ub960 \n",
      "    \n",
      "    numTrainDocs = len(trainMatrix) # 6\uac1c \n",
      "    numWords = len(trainMatrix[0])  # 32\uac1c \n",
      "    # sum(trainCategory): 3\uac1c  pAbusive: 0.5\n",
      "    pAbusive = sum(trainCategory)/float(numTrainDocs) #\uc0ac\uc804\ud655\ub960 (=\ubaa8\uc695\uc801\uc778 \ub9d0\uc774 \ub098\uc628 \ud655\ub960 ) Base Rate ,Frame theory, Anchor \n",
      "    p0Num = ones(numWords); p1Num = ones(numWords)      #change to ones()  \n",
      "    p0Denom = 2.0; p1Denom = 2.0                        #change to 2.0\n",
      "    # \ubca1\ud130 \ucd94\uac00 \n",
      "    for i in range(numTrainDocs):\n",
      "        if trainCategory[i] == 1:\n",
      "            p1Num += trainMatrix[i]\n",
      "            p1Denom += sum(trainMatrix[i])\n",
      "        else:\n",
      "            p0Num += trainMatrix[i]\n",
      "            p0Denom += sum(trainMatrix[i])\n",
      "    p1Vect = log(p1Num/p1Denom)          #change to log()\n",
      "    p0Vect = log(p0Num/p0Denom)          #change to log()\n",
      "    \n",
      "   # print pAbusive\n",
      "   # print p0Vect\n",
      "   # print p1Vect\n",
      "    return p0Vect,p1Vect,pAbusive\n",
      "\n",
      "trainMat = []\n",
      "\n",
      "for postinDoc in listoPosts:\n",
      "    trainMat.append(bayes.setOfWords2Vec(myVocabList, postinDoc))\n",
      "\n",
      "\n",
      "poV,p1V,pAb=trainNB0(trainMat, listclasses)\n",
      "print poV\n",
      "print p1V\n",
      "print pAb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[-2.56494936 -2.56494936 -2.56494936 -3.25809654 -3.25809654 -2.56494936\n",
        " -2.56494936 -2.56494936 -3.25809654 -2.56494936 -2.56494936 -2.56494936\n",
        " -2.56494936 -3.25809654 -3.25809654 -2.15948425 -3.25809654 -3.25809654\n",
        " -2.56494936 -3.25809654 -2.56494936 -2.56494936 -3.25809654 -2.56494936\n",
        " -2.56494936 -2.56494936 -3.25809654 -2.56494936 -3.25809654 -2.56494936\n",
        " -2.56494936 -1.87180218]\n",
        "[-3.04452244 -3.04452244 -3.04452244 -2.35137526 -2.35137526 -3.04452244\n",
        " -3.04452244 -3.04452244 -2.35137526 -2.35137526 -3.04452244 -3.04452244\n",
        " -3.04452244 -2.35137526 -2.35137526 -2.35137526 -2.35137526 -2.35137526\n",
        " -3.04452244 -1.94591015 -3.04452244 -2.35137526 -2.35137526 -3.04452244\n",
        " -1.94591015 -3.04452244 -1.65822808 -3.04452244 -2.35137526 -3.04452244\n",
        " -3.04452244 -3.04452244]\n",
        "0.5\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):\n",
      "    p1 = sum(vec2Classify * p1Vec) + log(pClass1)    #element-wise mult\n",
      "    p0 = sum(vec2Classify * p0Vec) + log(1.0 - pClass1)\n",
      "    if p1 > p0:\n",
      "        return 1\n",
      "    else: \n",
      "        return 0\n",
      "    \n",
      "def testingNB():\n",
      "    listOPosts,listClasses = bayes.loadDataSet()\n",
      "    myVocabList = createVocabList(listOPosts)\n",
      "    trainMat=[]\n",
      "    for postinDoc in listOPosts:\n",
      "        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))\n",
      "    p0V,p1V,pAb = trainNB0(array(trainMat),array(listClasses))\n",
      "    testEntry = ['love', 'my','stupid' ,'dalmation']\n",
      "    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))\n",
      "    print thisDoc\n",
      "    print testEntry,'classified as: ',classifyNB(thisDoc,p0V,p1V,pAb)\n",
      "    testEntry = ['stupid', 'garbage']\n",
      "    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))\n",
      "    print testEntry,'classified as: ',classifyNB(thisDoc,p0V,p1V,pAb)\n",
      "    \n",
      "#bayes.testingNB()\n",
      "testingNB()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1]\n",
        "['love', 'my', 'stupid', 'dalmation'] classified as:  0\n",
        "['stupid', 'garbage'] classified as:  1\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#classifying spam email with na\u00efve Bayes\n",
      "\n",
      "def bagOfWords2VecMN(vocabList, inputSet):\n",
      "    returnVec = [0]*len(vocabList)\n",
      "    for word in inputSet:\n",
      "        if word in vocabList:\n",
      "            returnVec[vocabList.index(word)] += 1\n",
      "    return returnVec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mySent = 'This book is the best book on Python or M.L. I have ever laid eyes upon.'\n",
      "mySent.split()\n",
      "\n",
      "import re\n",
      "regEx = re.compile('\\\\W*')\n",
      "listofTokens = regEx.split(mySent)\n",
      "listofTokens\n",
      "\n",
      "[tok.lower() for tok in listofTokens if len(tok)>0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "['this',\n",
        " 'book',\n",
        " 'is',\n",
        " 'the',\n",
        " 'best',\n",
        " 'book',\n",
        " 'on',\n",
        " 'python',\n",
        " 'or',\n",
        " 'm',\n",
        " 'l',\n",
        " 'i',\n",
        " 'have',\n",
        " 'ever',\n",
        " 'laid',\n",
        " 'eyes',\n",
        " 'upon']"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "emailText = open('email/spam/3.txt').read()\n",
      "listofTokens = regEx.split(emailText)\n",
      "listofTokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "['You',\n",
        " 'Have',\n",
        " 'Everything',\n",
        " 'To',\n",
        " 'Gain',\n",
        " 'Incredib1e',\n",
        " 'gains',\n",
        " 'in',\n",
        " 'length',\n",
        " 'of',\n",
        " '3',\n",
        " '4',\n",
        " 'inches',\n",
        " 'to',\n",
        " 'yourPenis',\n",
        " 'PERMANANTLY',\n",
        " 'Amazing',\n",
        " 'increase',\n",
        " 'in',\n",
        " 'thickness',\n",
        " 'of',\n",
        " 'yourPenis',\n",
        " 'up',\n",
        " 'to',\n",
        " '30',\n",
        " 'BetterEjacu1ation',\n",
        " 'control',\n",
        " 'Experience',\n",
        " 'Rock',\n",
        " 'HardErecetions',\n",
        " 'Explosive',\n",
        " 'intenseOrgasns',\n",
        " 'Increase',\n",
        " 'volume',\n",
        " 'ofEjacu1ate',\n",
        " 'Doctor',\n",
        " 'designed',\n",
        " 'and',\n",
        " 'endorsed',\n",
        " '100',\n",
        " 'herbal',\n",
        " '100',\n",
        " 'Natural',\n",
        " '100',\n",
        " 'Safe',\n",
        " 'The',\n",
        " 'proven',\n",
        " 'NaturalPenisEnhancement',\n",
        " 'that',\n",
        " 'works',\n",
        " '100',\n",
        " 'MoneyBack',\n",
        " 'Guaranteeed']"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def textParse(bigString):    #input is big string, #output is word list\n",
      "    import re\n",
      "    listOfTokens = re.split(r'\\W*', bigString)\n",
      "    return [tok.lower() for tok in listOfTokens if len(tok) > 2] \n",
      "    \n",
      "def spamTest():\n",
      "    docList=[]; classList = []; fullText =[]\n",
      "    for i in range(1,26):\n",
      "        wordList = textParse(open('email/spam/%d.txt' % i).read())\n",
      "        docList.append(wordList)\n",
      "        fullText.extend(wordList)\n",
      "        classList.append(1) #Label \ubd99\uc774\uae30 \n",
      "        wordList = textParse(open('email/ham/%d.txt' % i).read())\n",
      "        docList.append(wordList)\n",
      "        fullText.extend(wordList)\n",
      "        classList.append(0)\n",
      "    vocabList = createVocabList(docList)#create vocabulary\n",
      "    trainingSet = range(50); testSet=[]           #create test set\n",
      "    for i in range(10):\n",
      "        randIndex = int(random.uniform(0,len(trainingSet)))\n",
      "        testSet.append(trainingSet[randIndex])\n",
      "        del(trainingSet[randIndex])  \n",
      "    trainMat=[]; trainClasses = []\n",
      "    for docIndex in trainingSet:#train the classifier (get probs) trainNB0\n",
      "        trainMat.append(bagOfWords2VecMN(vocabList, docList[docIndex])) #\ub2e8\uc5b4\ub97c \ubca1\ud130\ub85c \ub9cc\ub4e4\uc5b4\uac00\ub294 \uacfc\uc815 \n",
      "        trainClasses.append(classList[docIndex])\n",
      "    p0V,p1V,pSpam = trainNB0(array(trainMat),array(trainClasses))\n",
      "    errorCount = 0\n",
      "    for docIndex in testSet:        #classify the remaining items\n",
      "        wordVector = bagOfWords2VecMN(vocabList, docList[docIndex]) #\ub2e8\uc5b4\ub4e4 \ubca1\ud130\ub85c \ub9cc\ub4e4\uc5b4\uac00\ub294 \uacfc\uc815 \n",
      "        if classifyNB(array(wordVector),p0V,p1V,pSpam) != classList[docIndex]:\n",
      "            errorCount += 1\n",
      "            print \"classification error\",docList[docIndex]\n",
      "    print 'the error rate is: ',float(errorCount)/len(testSet)\n",
      "   # print trainingSet\n",
      "   # print testSet\n",
      "        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#bayes.spamTest()\n",
      "spamTest()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "classification error ['home', 'based', 'business', 'opportunity', 'knocking', 'your', 'door', 'don', 'rude', 'and', 'let', 'this', 'chance', 'you', 'can', 'earn', 'great', 'income', 'and', 'find', 'your', 'financial', 'life', 'transformed', 'learn', 'more', 'here', 'your', 'success', 'work', 'from', 'home', 'finder', 'experts']\n",
        "the error rate is:  0.1\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import feedparser\n",
      "ny = feedparser.parse('http://newyork.craigslist.org/stp/index.rss')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ny['entries']\n",
      "len(ny['entries'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "25"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calcMostFreq(vocabList,fullText):\n",
      "    import operator\n",
      "    freqDict = {}\n",
      "    for token in vocabList:\n",
      "        freqDict[token]=fullText.count(token)\n",
      "    sortedFreq = sorted(freqDict.iteritems(), key=operator.itemgetter(1), reverse=True) \n",
      "    return sortedFreq[:30]       \n",
      "\n",
      "def localWords(feed1,feed0):\n",
      "    import feedparser\n",
      "    docList=[]; classList = []; fullText =[]\n",
      "    minLen = min(len(feed1['entries']),len(feed0['entries']))\n",
      "    for i in range(minLen):\n",
      "        wordList = textParse(feed1['entries'][i]['summary'])\n",
      "        docList.append(wordList)\n",
      "        fullText.extend(wordList)\n",
      "        classList.append(1) #NY is class 1\n",
      "        wordList = textParse(feed0['entries'][i]['summary'])\n",
      "        docList.append(wordList)\n",
      "        fullText.extend(wordList)\n",
      "        classList.append(0)\n",
      "    vocabList = createVocabList(docList)#create vocabulary\n",
      "    top30Words = calcMostFreq(vocabList,fullText)   #remove top 30 words\n",
      "    for pairW in top30Words:\n",
      "        if pairW[0] in vocabList: vocabList.remove(pairW[0])\n",
      "    trainingSet = range(2*minLen); testSet=[]           #create test set\n",
      "    for i in range(20):\n",
      "        randIndex = int(random.uniform(0,len(trainingSet)))\n",
      "        testSet.append(trainingSet[randIndex])\n",
      "        del(trainingSet[randIndex])  \n",
      "    trainMat=[]; trainClasses = []\n",
      "    for docIndex in trainingSet:#train the classifier (get probs) trainNB0\n",
      "        trainMat.append(bagOfWords2VecMN(vocabList, docList[docIndex]))\n",
      "        trainClasses.append(classList[docIndex])\n",
      "    p0V,p1V,pSpam = trainNB0(array(trainMat),array(trainClasses))\n",
      "    errorCount = 0\n",
      "    for docIndex in testSet:        #classify the remaining items\n",
      "        wordVector = bagOfWords2VecMN(vocabList, docList[docIndex])\n",
      "        if classifyNB(array(wordVector),p0V,p1V,pSpam) != classList[docIndex]:\n",
      "            errorCount += 1\n",
      "    print 'the error rate is: ',float(errorCount)/len(testSet)\n",
      "    return vocabList,p0V,p1V"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ny = feedparser.parse('http://newyork.craigslist.org/stp/index.rss')\n",
      "sf = feedparser.parse('http://sfbay.craigslist.org/stp/index.rss')\n",
      "vocabList,pSF,pNY=bayes.localWords(ny,sf)\n",
      "vocabList,pSF,pNY=bayes.localWords(ny,sf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "the error rate is:  0.45\n",
        "the error rate is: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.3\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}